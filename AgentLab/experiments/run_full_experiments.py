"""
å®Œæ•´å®éªŒ - è¿è¡Œæ‰€æœ‰Acidwaveä»»åŠ¡
=======================================

å‚è€ƒWebArenaçš„è¯„ä¼°æµç¨‹ï¼Œè¿è¡Œå…¨éƒ¨16ä¸ªä»»åŠ¡å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚

ç”¨æ³•:
    python experiments/run_full_experiments.py
    python experiments/run_full_experiments.py --difficulty easy
    python experiments/run_full_experiments.py --task-range 0 5
"""

import os
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

# CRITICAL: Patch AgentLab to support Acidwave tasks in Ray workers
import patch_agentlab

from benchmark.acidwave import AcidwaveBenchmark

# Set API key if not already set
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ é”™è¯¯: OPENAI_API_KEY æœªè®¾ç½®")
    print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åˆ›å»º .env æ–‡ä»¶")
    sys.exit(1)

from agentlab.experiments.study import make_study
from agentlab.experiments.loop import EnvArgs
from agents.acidwave_agent import ACIDWAVE_AGENT, ACIDWAVE_REASONING_AGENT


def run_full_experiments(
    task_ids=None,
    difficulty=None,
    agent=None,
    headless=True,
    slow_mo=100,
    max_steps=30,
    n_jobs=1,
    quiet=False,
):
    """
    è¿è¡Œå®Œæ•´çš„Acidwaveå®éªŒ
    
    Args:
        task_ids: è¦è¿è¡Œçš„ä»»åŠ¡IDåˆ—è¡¨ (None = å…¨éƒ¨)
        difficulty: æŒ‰éš¾åº¦ç­›é€‰ ("easy", "medium", "hard")
        agent: ä½¿ç”¨çš„Agent (é»˜è®¤: ACIDWAVE_AGENT)
        headless: æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
        slow_mo: æµè§ˆå™¨æ“ä½œå»¶è¿Ÿ (ms)
        max_steps: æ¯ä¸ªä»»åŠ¡æœ€å¤§æ­¥æ•°
        n_jobs: å¹¶è¡Œä»»åŠ¡æ•°
        quiet: é™é»˜æ¨¡å¼ï¼Œå‡å°‘ç»ˆç«¯è¾“å‡º
    """
    def log(msg="", level="info"):
        """æ¡ä»¶æ‰“å°å‡½æ•°"""
        if quiet and level == "info":
            return
        print(msg)
    
    log("\n" + "="*80)
    log("ACIDWAVE å®Œæ•´å®éªŒ - WebArenaé£æ ¼è¯„ä¼°")
    log("="*80)
    
    # Select agent
    if agent is None:
        agent = ACIDWAVE_AGENT
    
    log(f"\nğŸ¤– Agenté…ç½®:")
    log(f"   åç§°: {agent.agent_name}")
    log(f"   æ¨¡å‹: {agent.chat_model_args.model_name}")
    log(f"   æ¸©åº¦: {agent.chat_model_args.temperature}")
    
    # Load benchmark
    log("\n[1/6] åŠ è½½ä»»åŠ¡...")
    
    # Determine task subset
    if task_ids is not None:
        # Explicit task IDs
        benchmark = AcidwaveBenchmark(task_subset=task_ids)
        log(f"   ä½¿ç”¨æŒ‡å®šä»»åŠ¡: {task_ids}")
    elif difficulty is not None:
        # Filter by difficulty
        temp_benchmark = AcidwaveBenchmark()
        filtered_tasks = temp_benchmark.get_tasks_by_difficulty(difficulty)
        task_ids = [t["task_id"] for t in filtered_tasks]
        benchmark = AcidwaveBenchmark(task_subset=task_ids)
        log(f"   æŒ‰éš¾åº¦ç­›é€‰: {difficulty}")
        log(f"   åŒ¹é…ä»»åŠ¡: {len(task_ids)}ä¸ª")
    else:
        # All tasks
        benchmark = AcidwaveBenchmark()
        log(f"   åŠ è½½æ‰€æœ‰ä»»åŠ¡: {len(benchmark)}ä¸ª")
    
    # Show task details
    if not quiet:
        log(f"\n   ä»»åŠ¡è¯¦æƒ…:")
        for i, task in enumerate(benchmark):
            log(f"      [{task['task_id']}] ({task['difficulty']:6s}) {task['intent'][:50]}...")
    
    # Configure browser settings
    log(f"\nğŸ–¥ï¸  æµè§ˆå™¨é…ç½®:")
    log(f"   æ˜¾ç¤ºæ¨¡å¼: {'æ— å¤´' if headless else 'å¯è§†åŒ–'}")
    log(f"   æ“ä½œå»¶è¿Ÿ: {slow_mo}ms")
    log(f"   æœ€å¤§æ­¥æ•°: {max_steps}")
    log(f"   å¹¶è¡Œä»»åŠ¡: {n_jobs}")
    
    # Create study
    log("\n[2/6] åˆ›å»ºå®éªŒ...")
    
    try:
        # Create custom EnvArgs with settings
        custom_env_args_list = []
        for env_arg in benchmark.env_args_list:
            custom_env_arg = EnvArgs(
                task_name=env_arg.task_name,
                task_seed=env_arg.task_seed,
                task_kwargs=env_arg.task_kwargs,
                max_steps=max_steps,
                headless=headless,
                slow_mo=slow_mo,
                viewport={"width": 1280, "height": 720},
                record_video=False,
            )
            custom_env_args_list.append(custom_env_arg)
        
        benchmark.env_args_list = custom_env_args_list
        
        # Create study
        suffix = f"full_experiment"
        if difficulty:
            suffix += f"_{difficulty}"
        if task_ids and len(task_ids) < 16:
            suffix += f"_tasks{len(task_ids)}"
        
        study = make_study(
            agent_args=[agent],
            benchmark=benchmark,
            suffix=suffix,
            comment=f"å®Œæ•´è¯„ä¼°: {len(benchmark)}ä¸ªä»»åŠ¡",
        )
        log(f"   å®éªŒåç§°: {study.name}")
        log(f"   å®éªŒç›®å½•: {study.dir}")
        
    except Exception as e:
        print(f"   âŒ æ— æ³•åˆ›å»ºå®éªŒ: {e}")  # Always show errors
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # Check Acidwave is running
    log("\n[3/6] æ£€æŸ¥Acidwaveç¯å¢ƒ...")
    import requests
    try:
        response = requests.get("http://localhost:5173", timeout=3)
        if response.status_code == 200:
            log("   âœ… Acidwaveå‰ç«¯è¿è¡Œæ­£å¸¸")
        else:
            log(f"   âš ï¸  å‰ç«¯è¿”å›çŠ¶æ€ {response.status_code}")
    except requests.exceptions.RequestException:
        print("   âŒ æ— æ³•è¿æ¥åˆ°Acidwave!")  # Always show errors
        print("   è¯·å…ˆå¯åŠ¨: docker-compose up -d")
        response = input("\n   æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            sys.exit(1)
    
    # Run experiments
    log("\n[4/6] è¿è¡Œå®éªŒ...")
    log(f"   è¿™å¯èƒ½éœ€è¦ {len(benchmark) * 2}-{len(benchmark) * 5} åˆ†é’Ÿ...")
    
    if not headless and not quiet:
        log("\n   ğŸ’¡ æµè§ˆå™¨çª—å£ä¼šæ‰“å¼€,ä½ å¯ä»¥è§‚çœ‹agentçš„æ“ä½œ")
    
    try:
        study.run(n_jobs=n_jobs)
        log("   âœ… å®éªŒå®Œæˆ!")
    except Exception as e:
        print(f"   âŒ å®éªŒå¤±è´¥: {e}")  # Always show errors
        print(f"\n   æŸ¥çœ‹æ—¥å¿—: {study.dir}")
        sys.exit(1)
    
    # Analyze results
    log("\n[5/6] åˆ†æç»“æœ...")
    from agentlab.analyze import inspect_results
    
    summary_file = None  # Initialize to avoid UnboundLocalError
    
    try:
        result_df = inspect_results.load_result_df(study.dir)

        # Enrich with difficulty if missing
        if "difficulty" not in result_df.columns:
            difficulty_map = {
                f"acidwave.task_{t['task_id']}": t.get("difficulty", "unknown")
                for t in benchmark
            }

            # Try to find a task identifier column
            task_col = None
            for candidate in ["task_name", "env_name", "task", "env_id"]:
                if candidate in result_df.columns:
                    task_col = candidate
                    break

            if task_col:
                result_df["difficulty"] = result_df[task_col].map(
                    lambda tn: difficulty_map.get(tn, "unknown")
                )
            else:
                # Fallback: fill with unknown to avoid KeyError in downstream analysis
                result_df["difficulty"] = "unknown"
        
        log("\n" + "="*80)
        log("å®éªŒç»“æœ")
        log("="*80)
        
        # Overall metrics
        total = len(result_df)
        success_count = (result_df["cum_reward"] > 0.8).sum()
        partial_count = ((result_df["cum_reward"] > 0.3) & 
                        (result_df["cum_reward"] <= 0.8)).sum()
        fail_count = (result_df["cum_reward"] <= 0.3).sum()
        
        success_rate = (success_count / total * 100) if total > 0 else 0
        
        # Always show key results
        print(f"\nğŸ“Š æ€»ä½“è¡¨ç°:")
        print(f"   æˆåŠŸ: {success_count:2d} / {total} ({success_rate:5.1f}%)")
        print(f"   éƒ¨åˆ†: {partial_count:2d} / {total}")
        print(f"   å¤±è´¥: {fail_count:2d} / {total}")
        
        # By difficulty
        if not quiet and ("difficulty" in result_df.columns or len(benchmark._tasks) > 0):
            print(f"\nğŸ“ˆ æŒ‰éš¾åº¦åˆ†æ:")
            
            # Add difficulty to results - check for task_name column
            if 'task_name' in result_df.columns:
                task_difficulty = {
                    f"acidwave.task_{t['task_id']}": t['difficulty']
                    for t in benchmark._tasks
                }
                result_df['difficulty'] = result_df['task_name'].map(task_difficulty)
            elif 'exp_args.env_args.task_name' in result_df.columns:
                # Alternative column name
                task_difficulty = {
                    f"acidwave.task_{t['task_id']}": t['difficulty']
                    for t in benchmark._tasks
                }
                result_df['difficulty'] = result_df['exp_args.env_args.task_name'].map(task_difficulty)
            
            for diff in ["easy", "medium", "hard"]:
                diff_tasks = result_df[result_df['difficulty'] == diff]
                if len(diff_tasks) > 0:
                    diff_success = (diff_tasks["cum_reward"] > 0.8).sum()
                    diff_total = len(diff_tasks)
                    diff_rate = (diff_success / diff_total * 100) if diff_total > 0 else 0
                    print(f"   {diff:6s}: {diff_success:2d}/{diff_total:2d} ({diff_rate:5.1f}%)")
        
        # Per-task details
        if not quiet:
            print(f"\nğŸ“ ä»»åŠ¡è¯¦æƒ…:")
            
            # Find the task name column
            task_col = None
            for col in ['task_name', 'exp_args.env_args.task_name']:
                if col in result_df.columns:
                    task_col = col
                    break
            
            for _, row in result_df.iterrows():
                if task_col:
                    task_name = row.get(task_col, "Unknown")
                else:
                    task_name = "Unknown"
                    
                task_id = task_name.split("_")[-1] if "_" in task_name else "?"
                reward = row.get("cum_reward", 0)
                steps = row.get("n_steps", 0)
                error = row.get("err_msg", "")
                
                # Status icon
                if reward > 0.8:
                    status = "âœ…"
                elif reward > 0.3:
                    status = "ğŸ”¶"
                else:
                    status = "âŒ"
                
                # Get task difficulty
                diff = row.get("difficulty", "?")
                
                print(f"   {status} ä»»åŠ¡ {task_id} ({diff:6s}): å¾—åˆ†={reward:.2f}, æ­¥æ•°={steps}")
                if error and reward <= 0.8:
                    print(f"      é”™è¯¯: {error[:70]}")
        
        # Save summary
        log("\n[6/6] ä¿å­˜æŠ¥å‘Š...")
        
        # Summary file
        summary_file = study.dir / "experiment_summary.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("ACIDWAVE å®éªŒæ€»ç»“\n")
            f.write("="*80 + "\n\n")
            f.write(f"Agent: {agent.agent_name}\n")
            f.write(f"Model: {agent.chat_model_args.model_name}\n")
            f.write(f"Tasks: {total}\n\n")
            f.write(f"æˆåŠŸç‡: {success_rate:.1f}% ({success_count}/{total})\n")
            f.write(f"éƒ¨åˆ†å®Œæˆ: {partial_count}/{total}\n")
            f.write(f"å¤±è´¥: {fail_count}/{total}\n\n")
            f.write("="*80 + "\n")
            f.write("è¯¦ç»†ç»“æœ\n")
            f.write("="*80 + "\n\n")
            f.write(result_df.to_string())
        
        log(f"   âœ… æ€»ç»“å·²ä¿å­˜: {summary_file}")
        
        # CSV export
        csv_file = study.dir / "results.csv"
        result_df.to_csv(csv_file, index=False)
        log(f"   âœ… CSVå·²å¯¼å‡º: {csv_file}")
        
    except Exception as e:
        print(f"   âš ï¸  æ— æ³•åˆ†æç»“æœ: {e}")  # Always show errors
        import traceback
        traceback.print_exc()
    
    # Final summary
    log("\n" + "="*80)
    log("å®éªŒå®Œæˆ!")
    log("="*80)
    print(f"\nğŸ“ ç»“æœç›®å½•: {study.dir}")  # Always show final results
    
    if not quiet:
        log("\nğŸ“Š ä¸‹ä¸€æ­¥:")
        if summary_file:
            log("   1. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š:")
            log(f"      cat {summary_file}")
        log("   2. æŸ¥çœ‹å¤±è´¥ä»»åŠ¡çš„æˆªå›¾:")
        log(f"      cd {study.dir}")
        log("      ls */screenshot_*.png")
        log("   3. ä½¿ç”¨AgentXrayå¯è§†åŒ–:")
        log("      agentlab-xray")
        log("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        try:
            # Try to get success_rate from earlier
            if 'success_rate' in locals():
                if success_rate < 50:
                    log("   - æˆåŠŸç‡è¾ƒä½,è€ƒè™‘:")
                    log("     â€¢ æ”¹è¿›agentæç¤ºè¯")
                    log("     â€¢ å¢åŠ max_steps")
                    log("     â€¢ ä½¿ç”¨ACIDWAVE_REASONING_AGENT")
                elif success_rate < 80:
                    log("   - æˆåŠŸç‡ä¸­ç­‰,è€ƒè™‘:")
                    log("     â€¢ è°ƒæ•´temperatureå‚æ•°")
                    log("     â€¢ æ”¹è¿›éªŒè¯é€»è¾‘")
                else:
                    log("   - æˆåŠŸç‡å¾ˆå¥½! å¯ä»¥:")
                    log("     â€¢ å°è¯•æ›´éš¾çš„ä»»åŠ¡")
                    log("     â€¢ ä¼˜åŒ–æ­¥æ•°æ•ˆç‡")
        except:
            pass


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="è¿è¡Œå®Œæ•´çš„Acidwaveå®éªŒ (WebArenaé£æ ¼)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è¿è¡Œæ‰€æœ‰ä»»åŠ¡
  python experiments/run_full_experiments.py
  
  # åªè¿è¡Œç®€å•ä»»åŠ¡
  python experiments/run_full_experiments.py --difficulty easy
  
  # è¿è¡ŒæŒ‡å®šä»»åŠ¡èŒƒå›´
  python experiments/run_full_experiments.py --task-range 0 5
  
  # ä½¿ç”¨æ¨ç†agent
  python experiments/run_full_experiments.py --agent reasoning
  
  # å¯è§†åŒ–æ¨¡å¼ (æ˜¾ç¤ºæµè§ˆå™¨)
  python experiments/run_full_experiments.py --no-headless --slow-mo 1000
  
  # å¹¶è¡Œè¿è¡Œ (éœ€è¦è¶³å¤Ÿçš„èµ„æº)
  python experiments/run_full_experiments.py --n-jobs 3
        """
    )
    
    parser.add_argument(
        '--difficulty',
        choices=['easy', 'medium', 'hard'],
        help='æŒ‰éš¾åº¦ç­›é€‰ä»»åŠ¡'
    )
    
    parser.add_argument(
        '--task-range',
        nargs=2,
        type=int,
        metavar=('START', 'END'),
        help='è¿è¡Œä»»åŠ¡IDèŒƒå›´ (ä¾‹å¦‚: 0 5 è¡¨ç¤ºä»»åŠ¡0-4)'
    )
    
    parser.add_argument(
        '--task-ids',
        nargs='+',
        type=int,
        help='æŒ‡å®šä»»åŠ¡IDåˆ—è¡¨ (ä¾‹å¦‚: 0 2 5 7)'
    )
    
    parser.add_argument(
        '--agent',
        choices=['standard', 'reasoning', 'fast'],
        default='standard',
        help='é€‰æ‹©agentç±»å‹ (é»˜è®¤: standard)'
    )
    
    parser.add_argument(
        '--no-headless',
        action='store_true',
        help='æ˜¾ç¤ºæµè§ˆå™¨çª—å£'
    )
    
    parser.add_argument(
        '--slow-mo',
        type=int,
        default=100,
        help='æµè§ˆå™¨æ“ä½œå»¶è¿Ÿ (ms, é»˜è®¤: 100)'
    )
    
    parser.add_argument(
        '--max-steps',
        type=int,
        default=30,
        help='æ¯ä¸ªä»»åŠ¡æœ€å¤§æ­¥æ•° (é»˜è®¤: 30)'
    )
    
    parser.add_argument(
        '--n-jobs',
        type=int,
        default=1,
        help='å¹¶è¡Œè¿è¡Œçš„ä»»åŠ¡æ•° (é»˜è®¤: 1, é¡ºåºæ‰§è¡Œ)'
    )
    
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼Œå‡å°‘ç»ˆç«¯è¾“å‡º'
    )
    
    args = parser.parse_args()
    
    # Determine task IDs
    task_ids = None
    if args.task_ids:
        task_ids = args.task_ids
    elif args.task_range:
        start, end = args.task_range
        task_ids = list(range(start, end))
    
    # Select agent
    from agents.acidwave_agent import ACIDWAVE_FAST_AGENT
    agent_map = {
        'standard': ACIDWAVE_AGENT,
        'reasoning': ACIDWAVE_REASONING_AGENT,
        'fast': ACIDWAVE_FAST_AGENT,
    }
    agent = agent_map[args.agent]
    
    # Run experiments
    run_full_experiments(
        task_ids=task_ids,
        difficulty=args.difficulty,
        agent=agent,
        headless=not args.no_headless,
        slow_mo=args.slow_mo,
        max_steps=args.max_steps,
        n_jobs=args.n_jobs,
        quiet=args.quiet,
    )


if __name__ == "__main__":
    main()
